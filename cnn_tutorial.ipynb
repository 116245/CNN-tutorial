{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks Tutorial\n",
    "\n",
    "In this notebook, you will:\n",
    "\n",
    "- Implement helper functions that you will use when implementing a PyTorch model\n",
    "- Implement a fully functioning ConvNet using PyTorch \n",
    "\n",
    "**After this assignment you will be able to:**\n",
    "\n",
    "- Build and train a ConvNet in PyTorch for a classification problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Outline of the Assignment\n",
    "\n",
    "You will be implementing the building blocks of a convolutional neural network! Each function you will implement will have detailed instructions that will walk you through the steps needed:\n",
    "\n",
    "- Convolution functions\n",
    "\n",
    "- Pooling functions\n",
    "\n",
    "    \n",
    "In this next notebook, you will use the PyTorch equivalents of these functions to build the following model:\n",
    "\n",
    "<img src=\"images/model.png\" style=\"width:800px;height:300px;\">\n",
    "\n",
    "**Note** that for every forward function, there is its corresponding backward equivalent. Hence, at every step of your forward module you will store some parameters in a cache. These parameters are used to compute gradients during backpropagation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Convolutional Neural Networks\n",
    "\n",
    "Although programming frameworks make convolutions easy to use, they remain one of the hardest concepts to understand in Deep Learning. A convolution layer transforms an input volume into an output volume of different size, as shown below. \n",
    "\n",
    "<img src=\"images/conv_nn.png\" style=\"width:350px;height:200px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 - Zero-Padding\n",
    "\n",
    "Zero-padding adds zeros around the border of an image:\n",
    "\n",
    "<img src=\"images/PAD.png\" style=\"width:600px;height:400px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 1** </u><font color='purple'>  : **Zero-Padding**<br> Image (3 channels, RGB) with a padding of 2. </center></caption>\n",
    "\n",
    "The main benefits of padding are the following:\n",
    "\n",
    "- It allows you to use a CONV layer without necessarily shrinking the height and width of the volumes. This is important for building deeper networks, since otherwise the height/width would shrink as you go to deeper layers. An important special case is the \"same\" convolution, in which the height/width is exactly preserved after one layer. \n",
    "\n",
    "- It helps us keep more of the information at the border of an image. Without padding, very few values at the next layer would be affected by pixels as the edges of an image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 - Single step of convolution \n",
    "\n",
    "In this part, implement a single step of convolution, in which you apply the filter to a single position of the input. This will be used to build a convolutional unit, which: \n",
    "\n",
    "- Takes an input volume \n",
    "- Applies a filter at every position of the input\n",
    "- Outputs another volume (usually of different size)\n",
    "\n",
    "<img src=\"images/Convolution_schematic.gif\" style=\"width:500px;\">\n",
    "<caption><center> <u> <font color='purple'> **Figure 2** </u><font color='purple'>  : **Convolution operation**<br> with a filter of 3x3 and a stride of 1 (stride = amount you move the window each time you slide) </center></caption>\n",
    "\n",
    "In a computer vision application, each value in the matrix on the left corresponds to a single pixel value, and we convolve a 3x3 filter with the image by multiplying its values element-wise with the original matrix, then summing them up and adding a bias. In this first step of the exercise, you will implement a single step of convolution, corresponding to applying a filter to just one of the positions to get a single real-valued output. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a running demo of a CONV layer. Since 3D volumes are hard to visualize, all the volumes (the input volume (in blue), the weight volumes (in red), the output volume (in green)) are visualized with each depth slice stacked in rows. The input volume is of size W1=5, H1=5, D1=3, we have two filters of size 3×3, and they are applied with a stride of 2. \n",
    "<img src=\"images/mulinput.gif\" style=\"width:600px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference：\n",
    "<a href=\"http://cs231n.github.io/convolutional-networks/\">http://cs231n.github.io/convolutional-networks/</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 - Convolutional Neural Networks - Forward pass\n",
    "\n",
    "In the forward pass, you will take many filters and convolve them on the input. Each 'convolution' gives you a 2D matrix output. You will then stack these outputs to get a 3D volume: \n",
    "\n",
    "<center>\n",
    "<video width=\"620\" height=\"440\" src=\"images/conv_kiank.mp4\" type=\"video/mp4\" controls>\n",
    "</video>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Pooling layer \n",
    "\n",
    "The pooling (POOL) layer reduces the height and width of the input. It helps reduce computation, as well as helps make feature detectors more invariant to its position in the input. The two types of pooling layers are: \n",
    "\n",
    "- Max-pooling layer: slides an ($f, f$) window over the input and stores the max value of the window in the output.\n",
    "\n",
    "- Average-pooling layer: slides an ($f, f$) window over the input and stores the average value of the window in the output.\n",
    "\n",
    "<table>\n",
    "<td>\n",
    "<img src=\"images/max_pool1.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "\n",
    "<td>\n",
    "<img src=\"images/a_pool.png\" style=\"width:500px;height:300px;\">\n",
    "<td>\n",
    "</table>\n",
    "\n",
    "These pooling layers have no parameters for backpropagation to train. However, they have hyperparameters such as the window size $f$. This specifies the height and width of the fxf window you would compute a max or average over. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `ipynb` notebook and slides associated with <a href=\"http://deeplearning.ai\">deeplearning.ai</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - PyTorch model\n",
    "\n",
    "Most practical applications of deep learning today are built using programming frameworks, which have many built-in functions you can simply call. \n",
    "\n",
    "As usual, we will start by loading in the packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import datetime\n",
    "import torch\n",
    "import torchtext.data as data\n",
    "import torchtext.datasets as datasets\n",
    "#import mydatasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#dataset\n",
    "import re\n",
    "import random\n",
    "import tarfile\n",
    "import urllib\n",
    "from torchtext import data\n",
    "\n",
    "#model\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#train\n",
    "import sys\n",
    "import torch.autograd as autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to add parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial learning rate\n",
    "lr = 0.001\n",
    "#number of epochs for train\n",
    "epochs =  50\n",
    "#batch size for training\n",
    "batch_size = 64\n",
    "#how many steps to wait before logging training status\n",
    "log_interval = 1\n",
    "#how many steps to wait before testing\n",
    "test_interval=50\n",
    "#iteration numbers to stop without performance increasing\n",
    "early_stop = 1000\n",
    "# data \n",
    "#shuffle the data every epoch\n",
    "shuffle = False\n",
    "# model\n",
    "#the probability for dropout\n",
    "dropout = 0.5\n",
    "#constraint of parameters\n",
    "max_norm = 3.0\n",
    "#number of embedding dimension\n",
    "embed_dim = 128\n",
    "#number of each kind of kernel\n",
    "kernel_num =100\n",
    "#comma-separated kernel size to use for convolution\n",
    "kernel_sizes = '3,4,5'\n",
    "#fix the embedding\n",
    "static = False\n",
    "# device\n",
    "#device to use for iterate data, -1 mean cpu [default: -1]\n",
    "device = -1\n",
    "#disable the gpu\n",
    "no_cuda = False\n",
    "# option\n",
    "#train or test\n",
    "test = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Movie Review data from Rotten Tomatoes**\n",
    "- Classify that the review is positive/negative\n",
    "- Statistics\n",
    "<img src=\"images/mrdataset.png\" style=\"width:700px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preprocessing on text**\n",
    "- Remove special symbol by regular expression\n",
    "- Split sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the next cell to load the \"movie review\" dataset you are going to use.\n",
    "\n",
    "As a reminder,the Movie Review data from Rotten Tomatoes classify that the review is positive/negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MR(data.Dataset):\n",
    "\n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "\n",
    "    def __init__(self, text_field, label_field, path=None, examples=None, **kwargs):\n",
    "       \n",
    "        def clean_str(string):\n",
    "            \"\"\"\n",
    "            Tokenization/string cleaning for all datasets except for SST.\n",
    "            Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "            \"\"\"\n",
    "            string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "            string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "            string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "            string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "            string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "            string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "            string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "            string = re.sub(r\",\", \" , \", string)\n",
    "            string = re.sub(r\"!\", \" ! \", string)\n",
    "            string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "            string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "            string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "            string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "            return string.strip()\n",
    "\n",
    "        text_field.preprocessing = data.Pipeline(clean_str)\n",
    "        fields = [('text', text_field), ('label', label_field)]\n",
    "\n",
    "        if examples is None:\n",
    "            path = self.dirname if path is None else path\n",
    "            examples = []\n",
    "            with open(os.path.join(path, 'rt-polarity.neg'), errors='ignore') as f:\n",
    "                examples += [\n",
    "                    data.Example.fromlist([line, 'negative'], fields) for line in f]\n",
    "            with open(os.path.join(path, 'rt-polarity.pos'), errors='ignore') as f:\n",
    "                examples += [\n",
    "                    data.Example.fromlist([line, 'positive'], fields) for line in f]\n",
    "        super(MR, self).__init__(examples, fields, **kwargs)\n",
    "\n",
    "    @classmethod\n",
    "    def splits(cls, text_field, label_field, dev_ratio=.1, shuffle=True, **kwargs):\n",
    "        \"\"\"Create dataset objects for splits of the MR dataset.\n",
    "\n",
    "        Arguments:\n",
    "            text_field: The field that will be used for the sentence.\n",
    "            label_field: The field that will be used for label data.\n",
    "            dev_ratio: The ratio that will be used to get split validation dataset.\n",
    "            shuffle: Whether to shuffle the data before split.\n",
    "\n",
    "        \"\"\"\n",
    "        path = \"./rt-polaritydata/\"\n",
    "        examples = cls(text_field, label_field, path=path, **kwargs).examples\n",
    "        if shuffle: random.shuffle(examples)\n",
    "        dev_index = -1 * int(dev_ratio*len(examples))\n",
    "\n",
    "        return (cls(text_field, label_field, examples=examples[:dev_index]),\n",
    "                cls(text_field, label_field, examples=examples[dev_index:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MR dataset\n",
    "def mr(text_field, label_field, **kargs):\n",
    "    train_data, dev_data = MR.splits(text_field, label_field)\n",
    "    text_field.build_vocab(train_data, dev_data)\n",
    "    label_field.build_vocab(train_data, dev_data)\n",
    "    train_iter, dev_iter = data.Iterator.splits(\n",
    "                                (train_data, dev_data), \n",
    "                                batch_sizes=(batch_size, len(dev_data)),\n",
    "                                **kargs)\n",
    "    return train_iter, dev_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_field = data.Field(lower=True)\n",
    "label_field = data.Field(sequential=False)\n",
    "train_iter, dev_iter = mr(text_field, label_field, device=-1, repeat=False)\n",
    "# train_iter, dev_iter, test_iter = sst(text_field, label_field, device=-1, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_num = len(text_field.vocab)\n",
    "class_num = len(label_field.vocab) - 1\n",
    "cuda = (not no_cuda) and torch.cuda.is_available(); del no_cuda\n",
    "kernel_sizes = [int(k) for k in kernel_sizes.split(',')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "The network we will build in this post looks roughly as follows:\n",
    "\n",
    "<img src=\"images/textcnn.png\" style=\"height:300px;\">\n",
    "\n",
    "The first layers embeds words into low-dimensional vectors. The next layer performs convolutions over the embedded word vectors using multiple filter sizes. For example, sliding over 3, 4 or 5 words at a time. Next, we max-pool the result of the convolutional layer into a long feature vector, add dropout regularization, and classify the result using a softmax layer, and we will not used pre-trained word2vec vectors for our word embeddings. Instead, we learn embeddings from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Text(nn.Module):\n",
    "    \n",
    "    def __init__(self, lr,epochs,batch_size,log_interval,test_interval,early_stop,shuffle,dropout\\\n",
    "                 ,max_norm,embed_dim,kernel_num,kernel_sizes,static,device,no_cuda,test):\n",
    "        super(CNN_Text, self).__init__()\n",
    "        \n",
    "        V = embed_num\n",
    "        D = embed_dim\n",
    "        C = class_num\n",
    "        Ci = 1\n",
    "        Co = kernel_num\n",
    "        Ks = kernel_sizes\n",
    "        \n",
    "        self.embed = nn.Embedding(V, D)\n",
    "        # self.convs1 = [nn.Conv2d(Ci, Co, (K, D)) for K in Ks]\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(Ci, Co, (K, D)) for K in Ks])\n",
    "        '''\n",
    "        self.conv13 = nn.Conv2d(Ci, Co, (3, D))\n",
    "        self.conv14 = nn.Conv2d(Ci, Co, (4, D))\n",
    "        self.conv15 = nn.Conv2d(Ci, Co, (5, D))\n",
    "        '''\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(len(Ks)*Co, C)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = F.relu(conv(x)).squeeze(3)  # (N, Co, W)\n",
    "        x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embed(x)  # (N, W, D)\n",
    "        \n",
    "        if static:\n",
    "            x = Variable(x)\n",
    "\n",
    "        x = x.unsqueeze(1)  # (N, Ci, W, D)\n",
    "\n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1]  # [(N, Co, W), ...]*len(Ks)\n",
    "\n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  # [(N, Co), ...]*len(Ks)\n",
    "\n",
    "        x = torch.cat(x, 1)\n",
    "\n",
    "        '''\n",
    "        x1 = self.conv_and_pool(x,self.conv13) #(N,Co)\n",
    "        x2 = self.conv_and_pool(x,self.conv14) #(N,Co)\n",
    "        x3 = self.conv_and_pool(x,self.conv15) #(N,Co)\n",
    "        x = torch.cat((x1, x2, x3), 1) # (N,len(Ks)*Co)\n",
    "        '''\n",
    "        x = self.dropout(x)  # (N, len(Ks)*Co)\n",
    "        logit = self.fc1(x)  # (N, C)\n",
    "        return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter, dev_iter, model, lr,epochs,batch_size,log_interval,test_interval,early_stop,shuffle,dropout\\\n",
    "                 ,max_norm,embed_dim,kernel_num,kernel_sizes,static,device,no_cuda,test):\n",
    "    if cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    steps = 0\n",
    "    best_acc = 0\n",
    "    last_step = 0\n",
    "    accuracies = []\n",
    "    model.train()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        for batch in train_iter:\n",
    "            feature, target = batch.text, batch.label\n",
    "            feature.data.t_(), target.data.sub_(1)  # batch first, index align\n",
    "            if cuda:\n",
    "                feature, target = feature.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            logit = model(feature)\n",
    "\n",
    "            #print('logit vector', logit.size())\n",
    "            #print('target vector', target.size())\n",
    "            loss = F.cross_entropy(logit, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            steps += 1\n",
    "            if steps % log_interval == 0:\n",
    "                corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "                accuracy = 100.0 * corrects/batch.batch_size\n",
    "                sys.stdout.write(\n",
    "                    '\\rBatch[{}] - loss: {:.6f}  acc: {:.4f}%({}/{})'.format(steps, \n",
    "                                                                             loss.data[0], \n",
    "                                                                             accuracy,\n",
    "                                                                             corrects,\n",
    "                                                                             batch.batch_size))\n",
    "            if steps % test_interval == 0:\n",
    "                dev_acc = eval(dev_iter, model, cuda)\n",
    "                accuracies.append(dev_acc)\n",
    "                if dev_acc > best_acc:\n",
    "                    best_acc = dev_acc\n",
    "                    last_step = steps\n",
    "                else:\n",
    "                    if steps - last_step >= early_stop:\n",
    "                        print('early stop by {} steps.'.format(early_stop))\n",
    "\n",
    "                \n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(accuracies))\n",
    "    plt.ylabel('acc')\n",
    "    plt.xlabel('iterations')\n",
    "    plt.title(\"Learning rate =\" + str(lr))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def eval(data_iter, model, cuda):\n",
    "    model.eval()\n",
    "    corrects, avg_loss = 0, 0\n",
    "    for batch in data_iter:\n",
    "        feature, target = batch.text, batch.label\n",
    "        feature.data.t_(), target.data.sub_(1)  # batch first, index align\n",
    "        if cuda:\n",
    "            feature, target = feature.cuda(), target.cuda()\n",
    "\n",
    "        logit = model(feature)\n",
    "        loss = F.cross_entropy(logit, target, size_average=False)\n",
    "\n",
    "        avg_loss += loss.data[0]\n",
    "        corrects += (torch.max(logit, 1)\n",
    "                     [1].view(target.size()).data == target.data).sum()\n",
    "        \n",
    "    size = len(data_iter.dataset)\n",
    "    avg_loss /= size\n",
    "    accuracy = 100.0 * corrects/size\n",
    "    print('\\nEvaluation - loss: {:.6f}  acc: {:.4f}%({}/{}) \\n'.format(avg_loss, \n",
    "                                                                       accuracy, \n",
    "                                                                       corrects, \n",
    "                                                                       size))\n",
    "    \n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cuda = False\n",
    "cnn = CNN_Text(lr,epochs,batch_size,log_interval,test_interval,early_stop,shuffle,dropout\\\n",
    "               ,max_norm,embed_dim,kernel_num,kernel_sizes,static,device,no_cuda,test)\n",
    "\n",
    "if cuda:\n",
    "    torch.cuda.set_device(device)\n",
    "    cnn = cnn.cuda()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN_Text(\n",
      "  (embed): Embedding(21114, 128)\n",
      "  (convs1): ModuleList(\n",
      "    (0): Conv2d(1, 100, kernel_size=(3, 128), stride=(1, 1))\n",
      "    (1): Conv2d(1, 100, kernel_size=(4, 128), stride=(1, 1))\n",
      "    (2): Conv2d(1, 100, kernel_size=(5, 128), stride=(1, 1))\n",
      "  )\n",
      "  (dropout): Dropout(p=0.5)\n",
      "  (fc1): Linear(in_features=300, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(cnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ginko/.local/lib/python3.5/site-packages/ipykernel_launcher.py:34: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch[50] - loss: 0.722820  acc: 54.0000%(35/64)\n",
      "Evaluation - loss: 0.677804  acc: 55.0000%(593/1066) \n",
      "\n",
      "Batch[71] - loss: 0.703756  acc: 59.0000%(38/64)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ginko/.local/lib/python3.5/site-packages/torchtext/data/field.py:322: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  return Variable(arr, volatile=not train)\n",
      "/home/ginko/.local/lib/python3.5/site-packages/ipykernel_launcher.py:69: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch[100] - loss: 0.676690  acc: 62.0000%(40/64)\n",
      "Evaluation - loss: 0.661295  acc: 59.0000%(632/1066) \n",
      "\n",
      "Batch[150] - loss: 0.624592  acc: 70.0000%(42/60)\n",
      "Evaluation - loss: 0.636103  acc: 64.0000%(690/1066) \n",
      "\n",
      "Batch[200] - loss: 0.458721  acc: 81.0000%(52/64)\n",
      "Evaluation - loss: 0.621618  acc: 65.0000%(700/1066) \n",
      "\n",
      "Batch[250] - loss: 0.547412  acc: 75.0000%(48/64)\n",
      "Evaluation - loss: 0.607533  acc: 68.0000%(725/1066) \n",
      "\n",
      "Batch[300] - loss: 0.486583  acc: 75.0000%(45/60)\n",
      "Evaluation - loss: 0.606538  acc: 68.0000%(730/1066) \n",
      "\n",
      "Batch[350] - loss: 0.278782  acc: 90.0000%(58/64)\n",
      "Evaluation - loss: 0.599041  acc: 70.0000%(748/1066) \n",
      "\n",
      "Batch[400] - loss: 0.292396  acc: 93.0000%(60/64)\n",
      "Evaluation - loss: 0.606736  acc: 70.0000%(749/1066) \n",
      "\n",
      "Batch[450] - loss: 0.280801  acc: 86.0000%(52/60)\n",
      "Evaluation - loss: 0.610323  acc: 69.0000%(744/1066) \n",
      "\n",
      "Batch[500] - loss: 0.079090  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.624812  acc: 70.0000%(750/1066) \n",
      "\n",
      "Batch[550] - loss: 0.083433  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.645946  acc: 69.0000%(743/1066) \n",
      "\n",
      "Batch[600] - loss: 0.086078  acc: 96.0000%(58/60))\n",
      "Evaluation - loss: 0.653451  acc: 70.0000%(755/1066) \n",
      "\n",
      "Batch[650] - loss: 0.029593  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.672560  acc: 70.0000%(748/1066) \n",
      "\n",
      "Batch[700] - loss: 0.023388  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.685155  acc: 71.0000%(760/1066) \n",
      "\n",
      "Batch[750] - loss: 0.026057  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.694752  acc: 70.0000%(749/1066) \n",
      "\n",
      "Batch[800] - loss: 0.012807  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.711963  acc: 70.0000%(753/1066) \n",
      "\n",
      "Batch[850] - loss: 0.014224  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.722836  acc: 71.0000%(757/1066) \n",
      "\n",
      "Batch[900] - loss: 0.009505  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.735659  acc: 71.0000%(757/1066) \n",
      "\n",
      "Batch[950] - loss: 0.009120  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.747697  acc: 71.0000%(757/1066) \n",
      "\n",
      "Batch[1000] - loss: 0.008131  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.752350  acc: 71.0000%(762/1066) \n",
      "\n",
      "Batch[1050] - loss: 0.007735  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.772150  acc: 70.0000%(749/1066) \n",
      "\n",
      "Batch[1100] - loss: 0.005025  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.775124  acc: 70.0000%(756/1066) \n",
      "\n",
      "Batch[1150] - loss: 0.004799  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.784269  acc: 70.0000%(754/1066) \n",
      "\n",
      "Batch[1200] - loss: 0.006745  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.789976  acc: 71.0000%(759/1066) \n",
      "\n",
      "Batch[1250] - loss: 0.003310  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.797601  acc: 71.0000%(757/1066) \n",
      "\n",
      "Batch[1300] - loss: 0.003269  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.806785  acc: 71.0000%(764/1066) \n",
      "\n",
      "Batch[1350] - loss: 0.003304  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.814218  acc: 70.0000%(751/1066) \n",
      "\n",
      "Batch[1400] - loss: 0.001926  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.821193  acc: 70.0000%(754/1066) \n",
      "\n",
      "Batch[1450] - loss: 0.002661  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.824917  acc: 70.0000%(753/1066) \n",
      "\n",
      "Batch[1500] - loss: 0.002956  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.830691  acc: 71.0000%(759/1066) \n",
      "\n",
      "Batch[1550] - loss: 0.001790  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.839686  acc: 71.0000%(762/1066) \n",
      "\n",
      "Batch[1600] - loss: 0.002090  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.843979  acc: 71.0000%(759/1066) \n",
      "\n",
      "Batch[1650] - loss: 0.002231  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.849433  acc: 70.0000%(755/1066) \n",
      "\n",
      "Batch[1700] - loss: 0.001637  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.854429  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[1750] - loss: 0.001561  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.860930  acc: 71.0000%(757/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[1800] - loss: 0.001812  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.867337  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[1850] - loss: 0.001539  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.873066  acc: 70.0000%(755/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[1900] - loss: 0.001149  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.876144  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[1950] - loss: 0.001902  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.881456  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2000] - loss: 0.001245  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.886594  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2050] - loss: 0.001156  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.888929  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2100] - loss: 0.001235  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.897797  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2150] - loss: 0.000896  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.901576  acc: 71.0000%(758/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2200] - loss: 0.001024  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.906134  acc: 71.0000%(759/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2250] - loss: 0.000877  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.910695  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2300] - loss: 0.000929  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.916197  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2350] - loss: 0.000902  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.919830  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2400] - loss: 0.000933  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.921603  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2450] - loss: 0.000650  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.927116  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2500] - loss: 0.000669  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.930878  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2550] - loss: 0.000664  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.936798  acc: 71.0000%(757/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2600] - loss: 0.000630  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.940548  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2650] - loss: 0.000699  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.942424  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2700] - loss: 0.000591  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.947081  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2750] - loss: 0.000489  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.953104  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2800] - loss: 0.000635  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.955893  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2850] - loss: 0.000593  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.957305  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2900] - loss: 0.000458  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.962850  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[2950] - loss: 0.000508  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.968131  acc: 71.0000%(759/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3000] - loss: 0.000398  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.969348  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3050] - loss: 0.000319  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.974947  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3100] - loss: 0.000423  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.976206  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3150] - loss: 0.000422  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.980086  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3200] - loss: 0.000541  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.984166  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3250] - loss: 0.000451  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.988260  acc: 71.0000%(765/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3300] - loss: 0.000379  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 0.991179  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3350] - loss: 0.000321  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.995396  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3400] - loss: 0.000319  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 0.998008  acc: 71.0000%(759/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3450] - loss: 0.000329  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.000586  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3500] - loss: 0.000245  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.005140  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3550] - loss: 0.000315  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.007822  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3600] - loss: 0.000269  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.012073  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3650] - loss: 0.000225  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.015624  acc: 71.0000%(765/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3700] - loss: 0.000289  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.018972  acc: 71.0000%(759/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3750] - loss: 0.000209  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.022000  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3800] - loss: 0.000224  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.024284  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3850] - loss: 0.000230  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.028381  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3900] - loss: 0.000276  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.031236  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[3950] - loss: 0.000209  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.034839  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4000] - loss: 0.000212  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.036118  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4050] - loss: 0.000244  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.041459  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4100] - loss: 0.000167  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.045515  acc: 71.0000%(765/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4150] - loss: 0.000193  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.047202  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4200] - loss: 0.000184  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.049487  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4250] - loss: 0.000162  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.052990  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4300] - loss: 0.000138  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.055789  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4350] - loss: 0.000167  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.059112  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4400] - loss: 0.000136  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.063666  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4450] - loss: 0.000166  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.066196  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4500] - loss: 0.000127  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.068342  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4550] - loss: 0.000150  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.072822  acc: 71.0000%(758/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4600] - loss: 0.000115  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.074731  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4650] - loss: 0.000112  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.077593  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4700] - loss: 0.000096  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.080335  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4750] - loss: 0.000133  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.082226  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4800] - loss: 0.000103  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.085995  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4850] - loss: 0.000108  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.089547  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4900] - loss: 0.000081  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.092927  acc: 71.0000%(758/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[4950] - loss: 0.000098  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.094390  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5000] - loss: 0.000093  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.098155  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5050] - loss: 0.000111  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.100985  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5100] - loss: 0.000103  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.104146  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5150] - loss: 0.000091  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.107298  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5200] - loss: 0.000071  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.108774  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5250] - loss: 0.000064  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.111435  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5300] - loss: 0.000068  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.115528  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5350] - loss: 0.000075  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.116914  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5400] - loss: 0.000082  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.120343  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5450] - loss: 0.000073  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.123412  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5500] - loss: 0.000077  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.127566  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5550] - loss: 0.000082  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.128372  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5600] - loss: 0.000063  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.131022  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5650] - loss: 0.000066  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.133860  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5700] - loss: 0.000069  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.136880  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5750] - loss: 0.000052  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.140615  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5800] - loss: 0.000049  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.143325  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5850] - loss: 0.000060  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.144974  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5900] - loss: 0.000046  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.148195  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[5950] - loss: 0.000055  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.151235  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6000] - loss: 0.000044  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.153500  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6050] - loss: 0.000048  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.155454  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6100] - loss: 0.000048  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.160519  acc: 71.0000%(760/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6150] - loss: 0.000039  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.161915  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6200] - loss: 0.000043  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.165071  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6250] - loss: 0.000043  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.167248  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6300] - loss: 0.000054  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.169672  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6350] - loss: 0.000048  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.173155  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6400] - loss: 0.000040  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.175421  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6450] - loss: 0.000036  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.177716  acc: 71.0000%(761/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6500] - loss: 0.000032  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.180281  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6550] - loss: 0.000027  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.182473  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch[6600] - loss: 0.000031  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.186060  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6650] - loss: 0.000034  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.188515  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6700] - loss: 0.000029  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.191008  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6750] - loss: 0.000028  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.193768  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6800] - loss: 0.000032  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.197046  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6850] - loss: 0.000025  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.200081  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6900] - loss: 0.000027  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.201997  acc: 71.0000%(763/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[6950] - loss: 0.000028  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.203959  acc: 71.0000%(765/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[7000] - loss: 0.000030  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.207277  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[7050] - loss: 0.000029  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.210181  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[7100] - loss: 0.000019  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.213821  acc: 71.0000%(762/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[7150] - loss: 0.000027  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.216037  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[7200] - loss: 0.000027  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.217304  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[7250] - loss: 0.000020  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.220249  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[7300] - loss: 0.000021  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.221944  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[7350] - loss: 0.000026  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.225614  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[7400] - loss: 0.000021  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.229548  acc: 71.0000%(765/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[7450] - loss: 0.000023  acc: 100.0000%(64/64)\n",
      "Evaluation - loss: 1.230949  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n",
      "Batch[7500] - loss: 0.000024  acc: 100.0000%(60/60)\n",
      "Evaluation - loss: 1.232630  acc: 71.0000%(764/1066) \n",
      "\n",
      "early stop by 1000 steps.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    train(train_iter, dev_iter, cnn, lr,epochs,batch_size,log_interval,test_interval,early_stop,shuffle,dropout\\\n",
    "             ,max_norm,embed_dim,kernel_num,kernel_sizes,static,device,no_cuda,test)\n",
    "except KeyboardInterrupt:\n",
    "    print('\\n' + '-' * 89)\n",
    "    print('Exiting from training early')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: <a href=\"https://github.com/Shawn1993/cnn-text-classification-pytorch\">https://github.com/Shawn1993/cnn-text-classification-pytorch</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
